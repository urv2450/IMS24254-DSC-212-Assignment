{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYo/1tVZenJU7bEgzrdJBr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urv2450/IMS24254-DSC-212-Assignment/blob/main/DSc_212.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SocRX0OND1eA"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries we need\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as mp\n",
        "import numpy as np\n",
        "\n",
        "# 1. Initial Setup\n",
        "\n",
        "# A list of colors for our plots.\n",
        "plot_colors = ['red', 'blue', 'green', 'orange', 'purple', 'darkgreen', 'lightcoral', 'yellow', 'cyan']\n",
        "\n",
        "# This will help us position our plots in a grid (e.g., subplot 1, 2, 3...)\n",
        "plot_position = 0\n",
        "\n",
        "# Loading the graph\n",
        "G = nx.karate_club_graph()\n",
        "\n",
        "# We'll make a copy of the graph to draw on. We'll cut edges from this copy to show the communities separating.\n",
        "drawing_graph = G.copy()\n",
        "\n",
        "# A list to save the modularity score at each step\n",
        "modularity_scores = []\n",
        "\n",
        "# This dictionary will hold which community each node belongs to.\n",
        "node_community = {node: -1 for node in G.nodes()}\n",
        "\n",
        "# This will track which community a node was in at each iteration.\n",
        "# It's a dictionary where each node gets a list of tuples: (iteration_number, color_label)\n",
        "node_history = {node: [(0, \"null\")] for node in G.nodes()}\n",
        "\n",
        "# A list to hold the color name for each node, e.g., node_colors[0] = 'red'\n",
        "# This is just for plotting.\n",
        "node_colors = [0] * G.number_of_nodes()\n",
        "\n",
        "# A counter to give new communities a unique ID (0, 1, 2, 3...)\n",
        "community_counter = 0\n",
        "\n",
        "# 2. Helper functions\n",
        "\n",
        "def get_modularity_score(g):\n",
        "    \"\"\"\n",
        "    This calculates the modularity of a given graph (or subgraph).\n",
        "    It follows the math from the handout:\n",
        "    1. Build the modularity matrix B = A - (k*k^T / 2m)\n",
        "    2. Find the leading eigenvector 's' of B\n",
        "    3. Calculate the score: Q = (1 / 2m) * s^T * B * s\n",
        "    \"\"\"\n",
        "    # Get the node degrees, e.g., [(0, 16), (1, 9), ...]\n",
        "    degrees_list = np.array(g.degree)\n",
        "\n",
        "    # Get the adjacency matrix (as a 0/1 numpy array)\n",
        "    A = nx.adjacency_matrix(g).toarray()\n",
        "\n",
        "    # Get just the degree numbers (k)\n",
        "    k = degrees_list[:, 1]\n",
        "    k_col = k[:, np.newaxis]  # Make it a column vector (n x 1)\n",
        "\n",
        "    # Calculate the k*k^T matrix (outer product)\n",
        "    k_outer = k_col @ k_col.T\n",
        "\n",
        "    # Get 2m (sum of all degrees)\n",
        "    two_m = np.sum(k)\n",
        "\n",
        "    # Calculate the \"expected edges\" matrix P = k*k^T / 2m\n",
        "    P = k_outer / two_m\n",
        "\n",
        "    # The Modularity Matrix! B = A - P\n",
        "    B = A - P\n",
        "\n",
        "    # Get eigenvalues and eigenvectors. .eigh is good for symmetric matrices.\n",
        "    eigenvals, eigenvecs = np.linalg.eigh(B)\n",
        "\n",
        "    # Get the leading eigenvector (the one for the biggest eigenvalue)\n",
        "    s = eigenvecs[:, np.argmax(eigenvals)]\n",
        "    s_col = s[:, np.newaxis] # Make it a column vector\n",
        "\n",
        "    # Calculate the final modularity score\n",
        "    # We use (1 / two_m) which is the same as (1 / (2*a)) in your code\n",
        "    s_T = s_col.T\n",
        "    score = (1 / two_m) * float((s_T @ B @ s_col)[0, 0].real)\n",
        "\n",
        "    # Save this score to our global list\n",
        "    modularity_scores.append(score)\n",
        "\n",
        "def find_split(g):\n",
        "    \"\"\"\n",
        "    This function finds the best way to split a subgraph 'g' into two.\n",
        "    It calculates the modularity matrix B and its leading eigenvector 's'.\n",
        "    It then updates the global 'node_community' map with new community IDs.\n",
        "\n",
        "    This MODIFIES the global 'node_community' and 'community_counter'.\n",
        "    \"\"\"\n",
        "    global community_counter\n",
        "\n",
        "    # Get the list of nodes in this subgraph\n",
        "    nodes_in_g = list(g.nodes())\n",
        "    if not nodes_in_g: # If the subgraph is empty, just stop.\n",
        "        return\n",
        "\n",
        "    # Get degrees and adjacency matrix for *this subgraph*\n",
        "    degrees_list = np.array(g.degree)\n",
        "    A = nx.adjacency_matrix(g).toarray()\n",
        "\n",
        "    k = degrees_list[:, 1]\n",
        "    k_col = k[:, np.newaxis]\n",
        "\n",
        "    k_outer = k_col @ k_col.T\n",
        "    two_m = np.sum(k)\n",
        "\n",
        "    # Avoid division by zero if the subgraph has no edges\n",
        "    if two_m == 0:\n",
        "        return\n",
        "\n",
        "    P = k_outer / two_m\n",
        "    B = A - P\n",
        "\n",
        "    # Get eigenvalues and eigenvectors\n",
        "    eigenvals, eigenvecs = np.linalg.eigh(B)\n",
        "\n",
        "    # Get the leading eigenvector 's'\n",
        "    s = eigenvecs[:, np.argmax(eigenvals)]\n",
        "\n",
        "    # Now, split the nodes based on the sign of their entry in 's'\n",
        "    i = 0 # index for the eigenvector 's'\n",
        "    for node in nodes_in_g:\n",
        "        # If the number is positive, put it in the first new community\n",
        "        if s[i].real > 0:\n",
        "            node_community[node] = community_counter\n",
        "        # Otherwise, put it in the second new community\n",
        "        else:\n",
        "            node_community[node] = community_counter + 1\n",
        "        i += 1\n",
        "\n",
        "    # We used two new community IDs, so increment the counter by 2\n",
        "    community_counter += 2\n",
        "\n",
        "def split_into_subgraphs(g):\n",
        "    \"\"\"\n",
        "    This reads the global 'node_community' map and splits graph 'g'\n",
        "    into two new subgraphs based on the IDs we just assigned in 'find_split'.\n",
        "    \"\"\"\n",
        "    group_a_nodes = []\n",
        "    group_b_nodes = []\n",
        "\n",
        "    # Check if the node's community ID is even or odd\n",
        "    for node in g.nodes():\n",
        "        if node_community[node] % 2 == 0:\n",
        "            group_a_nodes.append(node)\n",
        "        else:\n",
        "            group_b_nodes.append(node)\n",
        "\n",
        "    # Create the new subgraphs (using the original graph 'G' to preserve all node properties)\n",
        "    subgraph_a = nx.subgraph(G, group_a_nodes)\n",
        "    subgraph_b = nx.subgraph(G, group_b_nodes)\n",
        "\n",
        "    return subgraph_a, subgraph_b\n",
        "\n",
        "def log_history(g, color_name):\n",
        "    \"\"\"\n",
        "    Updates the 'node_history' log for every node in subgraph 'g'.\n",
        "    This tells us which nodes were part of which split at which iteration.\n",
        "    \"\"\"\n",
        "    for node in g.nodes():\n",
        "        # Get the last iteration number for this node and add 1\n",
        "        last_iter = node_history[node][-1][0]\n",
        "        node_history[node].append((last_iter + 1, color_name))\n",
        "\n",
        "def is_indivisible(g):\n",
        "    \"\"\"\n",
        "    Checks if a subgraph should be split further.\n",
        "    In your original code, this just checks if all nodes in 'g'\n",
        "    have the same community ID.\n",
        "\n",
        "    NOTE: A better check (from the handout) would be to see if the\n",
        "    largest eigenvalue of B is <= 0. But we'll keep your logic!\n",
        "    \"\"\"\n",
        "    if nx.is_empty(g):\n",
        "        return True # Can't split an empty graph\n",
        "\n",
        "    communities = []\n",
        "    for node in g.nodes():\n",
        "        communities.append(node_community[node])\n",
        "\n",
        "    # If there's only 1 unique community ID, it's indivisible.\n",
        "    is_terminal = (len(set(communities)) == 1)\n",
        "    return is_terminal\n",
        "\n",
        "def cut_edges_between(group_a, group_b):\n",
        "    \"\"\"\n",
        "    Removes edges from our global 'drawing_graph' that\n",
        "    connect a node in group_a to a node in group_b.\n",
        "    \"\"\"\n",
        "    for node_a in group_a.nodes():\n",
        "        for node_b in group_b.nodes():\n",
        "            if drawing_graph.has_edge(node_a, node_b):\n",
        "                drawing_graph.remove_edge(node_a, node_b)\n",
        "\n",
        "# 3. The Main Recursive Splitter\n",
        "\n",
        "# Set up the figure for our iteration plots\n",
        "mp.figure(figsize=(20, 16))\n",
        "\n",
        "def run_recursive_splits(g):\n",
        "    \"\"\"\n",
        "    This is the main recursive function. It takes a graph 'g' and:\n",
        "    1. Splits it into two new subgraphs, 'group_a' and 'group_b'.\n",
        "    2. Logs this split for our metrics.\n",
        "    3. Updates the colors for plotting.\n",
        "    4. Draws the 'before' and 'after' plots for this split.\n",
        "    5. Calculates the new modularity score.\n",
        "    6. Calls itself on 'group_a' and 'group_b' to split them further.\n",
        "    \"\"\"\n",
        "    if nx.is_empty(g):\n",
        "        return  # Stop recursing if the graph is empty\n",
        "    else:\n",
        "        global plot_position\n",
        "        global node_colors\n",
        "\n",
        "        # 1. Find the split and update the global 'node_community' map\n",
        "        find_split(g)\n",
        "\n",
        "        # 2. Get the two new subgraphs based on the split\n",
        "        group_a, group_b = split_into_subgraphs(g)\n",
        "\n",
        "        # 3. This part (from your original code) re-calculates community IDs\n",
        "        #    for the *new* subgraphs. This prepares them for the *next* recursive call.\n",
        "        find_split(group_a)\n",
        "        find_split(group_b)\n",
        "\n",
        "        # 4. Log this iteration for our metric plots\n",
        "        log_history(group_a, \"blue\") # 'blue' is just a placeholder\n",
        "        log_history(group_b, \"red\")  # 'red' is just a placeholder\n",
        "\n",
        "        # 5. Update the global 'node_colors' list for plotting this step\n",
        "        for node in G.nodes():\n",
        "            if node in group_a.nodes():\n",
        "                node_colors[node] = plot_colors[plot_position]\n",
        "            if node in group_b.nodes():\n",
        "                node_colors[node] = plot_colors[plot_position + 1]\n",
        "\n",
        "        # 6. Draw the 'BEFORE' split plot\n",
        "        mp.subplot(2, 2, plot_position + 1)\n",
        "        nx.draw_spring(drawing_graph, with_labels=True, node_color=node_colors)\n",
        "        mp.title(f\"Iteration {plot_position // 2}: Before Split\")\n",
        "\n",
        "        # 7. Cut the edges on our 'drawing_graph' for the next plot\n",
        "        cut_edges_between(group_a, group_b)\n",
        "\n",
        "        # 8. Calculate the modularity of this new state\n",
        "        get_modularity_score(drawing_graph)\n",
        "\n",
        "        # 9. Draw the 'AFTER' split plot\n",
        "        mp.subplot(2, 2, plot_position + 2)\n",
        "        nx.draw_spring(drawing_graph, with_labels=True, node_color=node_colors)\n",
        "        mp.title(f\"Iteration {plot_position // 2}: After Split\")\n",
        "\n",
        "        # 10. Move to the next plot positions\n",
        "        plot_position += 2\n",
        "\n",
        "        # 11. Recurse!\n",
        "        #    We only continue if the new group is not empty\n",
        "        #    and is not \"indivisible\" (i.e., it's not a final community)\n",
        "        if not nx.is_empty(group_a) and not is_indivisible(group_a):\n",
        "            run_recursive_splits(group_a)\n",
        "        if not nx.is_empty(group_b) and not is_indivisible(group_b):\n",
        "            run_recursive_splits(group_b)\n",
        "\n",
        "# 4. Running the Algorithm\n",
        "\n",
        "# First, let's get the modularity of the *original* graph\n",
        "get_modularity_score(G)\n",
        "\n",
        "# Start the recursive splitting!\n",
        "run_recursive_splits(G)\n",
        "\n",
        "# Clean up the history log (remove the \"null\" entry we started with)\n",
        "for node in node_history.keys():\n",
        "    node_history[node].pop(0)\n",
        "\n",
        "# Find out how many iterations we actually ran\n",
        "max_iterations = 0\n",
        "for node in node_history.keys():\n",
        "    num_splits = len(node_history[node])\n",
        "    if num_splits > max_iterations:\n",
        "        max_iterations = num_splits\n",
        "\n",
        "# 5. Metrics for each iteration\n",
        "\n",
        "# These will store the metric dictionaries for each iteration.\n",
        "# e.g., degree_history[1] = {0: 0.5, 1: 0.3, ...}\n",
        "#       degree_history[2] = {0: 0.4, 1: 0.2, ...}\n",
        "iter_colors = {i: [] for i in range(1, max_iterations + 1)}\n",
        "degree_history = {i: {} for i in range(1, max_iterations + 1)}\n",
        "betweenness_history = {i: {} for i in range(1, max_iterations + 1)}\n",
        "closeness_history = {i: {} for i in range(1, max_iterations + 1)}\n",
        "clustering_history = {i: {} for i in range(1, max_iterations + 1)}\n",
        "\n",
        "def calculate_metrics_by_iteration(history_log, max_iter):\n",
        "    \"\"\"\n",
        "    This function rebuilds the subgraphs that existed at each\n",
        "    iteration and calculates the centrality metrics for them.\n",
        "\n",
        "    NOTE: The assignment asked for metrics on the *full* graph 'G'.\n",
        "    Your code calculates them on the *subgraphs* as they split.\n",
        "    This version keeps your original (and interesting!) logic.\n",
        "    \"\"\"\n",
        "    color_index = 0\n",
        "    for i in range(1, max_iter + 1):\n",
        "        group_red_nodes = []\n",
        "        group_blue_nodes = []\n",
        "\n",
        "        # Rebuild the groups for this iteration\n",
        "        for node in history_log.keys():\n",
        "            # Check the log entry for this iteration\n",
        "            if i <= len(history_log[node]):\n",
        "                log_entry = history_log[node][i-1] # (i-1) because lists are 0-indexed\n",
        "\n",
        "                if log_entry[1] == \"red\":\n",
        "                    group_red_nodes.append(node)\n",
        "                    iter_colors[i].append(plot_colors[color_index])\n",
        "                else:\n",
        "                    group_blue_nodes.append(node)\n",
        "                    iter_colors[i].append(plot_colors[color_index + 1])\n",
        "\n",
        "        # Create the subgraphs from that iteration\n",
        "        sub_a = nx.subgraph(G, group_red_nodes)\n",
        "        sub_b = nx.subgraph(G, group_blue_nodes)\n",
        "\n",
        "        # Calculate metrics for each subgraph and merge the results\n",
        "        # The | operator (Python 3.9+) is a clean way to merge two dictionaries\n",
        "        all_deg_c = nx.degree_centrality(sub_a) | nx.degree_centrality(sub_b)\n",
        "        degree_history[i] = dict(sorted(all_deg_c.items()))\n",
        "\n",
        "        all_bet_c = nx.betweenness_centrality(sub_a) | nx.betweenness_centrality(sub_b)\n",
        "        betweenness_history[i] = dict(sorted(all_bet_c.items()))\n",
        "\n",
        "        all_clo_c = nx.closeness_centrality(sub_a) | nx.closeness_centrality(sub_b)\n",
        "        closeness_history[i] = dict(sorted(all_clo_c.items()))\n",
        "\n",
        "        all_clus_co = nx.clustering(sub_a) | nx.clustering(sub_b)\n",
        "        clustering_history[i] = dict(sorted(all_clus_co.items()))\n",
        "\n",
        "        color_index += 2\n",
        "\n",
        "# Fill in the metric history dictionaries\n",
        "calculate_metrics_by_iteration(node_history, max_iterations)\n",
        "\n",
        "# This is a clever part from your code:\n",
        "# If a node wasn't in a split at iteration 2, it means\n",
        "# it was in a \"terminal\" community. We should carry over\n",
        "# its value from iteration 1 so the line plot continues.\n",
        "for node in G.nodes():\n",
        "    if node not in degree_history[2]:\n",
        "        degree_history[2][node] = degree_history[1][node]\n",
        "    if node not in betweenness_history[2]:\n",
        "        betweenness_history[2][node] = betweenness_history[1][node]\n",
        "    if node not in closeness_history[2]:\n",
        "        closeness_history[2][node] = closeness_history[1][node]\n",
        "    if node not in clustering_history[2]:\n",
        "        clustering_history[2][node] = clustering_history[1][node]\n",
        "\n",
        "# 6. Plotting Our Results\n",
        "\n",
        "# First, let's show the final communities\n",
        "mp.figure(figsize=(16, 10))\n",
        "\n",
        "# Plot 1: Show the final communities, but keep all original edges\n",
        "mp.subplot(1, 2, 1)\n",
        "# We use kamada_kawai_layout for a nice \"force-directed\" look\n",
        "nx.draw_kamada_kawai(G, with_labels=True, node_color=node_colors)\n",
        "mp.title(\"Final Communities (All Edges Shown)\")\n",
        "\n",
        "# Plot 2: Show the final communities with the \"cut\" edges removed\n",
        "# This uses the 'drawing_graph' we've been cutting edges from\n",
        "mp.subplot(1, 2, 2)\n",
        "nx.draw_spring(drawing_graph, with_labels=True, node_color=node_colors)\n",
        "mp.title(\"Final Communities (Inter-Community Edges Removed)\")\n",
        "mp.show()\n",
        "\n",
        "# --- Now, plot the evolution of metrics for each node ---\n",
        "\n",
        "# We'll need these to plot against\n",
        "iterations = [1, 2]\n",
        "all_nodes = sorted(list(G.nodes())) # Sort the nodes so the plots are tidy\n",
        "\n",
        "# Get the metric values for each iteration, sorted by node ID\n",
        "vals_iter1_deg = [degree_history[1][node] for node in all_nodes]\n",
        "vals_iter2_deg = [degree_history[2][node] for node in all_nodes]\n",
        "\n",
        "# Plot Degree Centrality\n",
        "mp.figure(figsize=(16, 10))\n",
        "for node in all_nodes:\n",
        "    # Make a list of this node's metric values, e.g., [0.5, 0.4]\n",
        "    y_values = [vals_iter1_deg[node], vals_iter2_deg[node]]\n",
        "    mp.plot(iterations, y_values, 'o-', label=f\"Node {node}\") # 'o-' adds markers\n",
        "mp.xlabel('Iterations')\n",
        "mp.ylabel('Degree Centrality')\n",
        "mp.legend(loc='center left', bbox_to_anchor=(1, 0.5)) # Move legend outside plot\n",
        "mp.title('Degree Centrality Evolution')\n",
        "mp.xticks(iterations) # Make sure x-axis only shows 1 and 2\n",
        "mp.show()\n",
        "\n",
        "# Get values for Betweenness\n",
        "vals_iter1_bet = [betweenness_history[1][node] for node in all_nodes]\n",
        "vals_iter2_bet = [betweenness_history[2][node] for node in all_nodes]\n",
        "\n",
        "# Plot Betweenness Centrality\n",
        "mp.figure(figsize=(16, 10))\n",
        "for node in all_nodes:\n",
        "    y_values = [vals_iter1_bet[node], vals_iter2_bet[node]]\n",
        "    mp.plot(iterations, y_values, 'o-', label=f\"Node {node}\")\n",
        "mp.xlabel('Iterations')\n",
        "mp.ylabel('Betweenness Centrality')\n",
        "mp.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "mp.title('Betweenness Centrality Evolution')\n",
        "mp.xticks(iterations)\n",
        "mp.show()\n",
        "\n",
        "# Get values for Closeness\n",
        "vals_iter1_clo = [closeness_history[1][node] for node in all_nodes]\n",
        "vals_iter2_clo = [closeness_history[2][node] for node in all_nodes]\n",
        "\n",
        "# Plot Closeness Centrality\n",
        "mp.figure(figsize=(16, 10))\n",
        "for node in all_nodes:\n",
        "    y_values = [vals_iter1_clo[node], vals_iter2_clo[node]]\n",
        "    mp.plot(iterations, y_values, 'o-', label=f\"Node {node}\")\n",
        "mp.xlabel('Iterations')\n",
        "mp.ylabel('Closeness Centrality')\n",
        "mp.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "mp.title('Closeness Centrality Evolution')\n",
        "mp.xticks(iterations)\n",
        "mp.show()\n",
        "\n",
        "# Get values for Clustering\n",
        "vals_iter1_clus = [clustering_history[1][node] for node in all_nodes]\n",
        "vals_iter2_clus = [clustering_history[2][node] for node in all_nodes]\n",
        "\n",
        "# Plot Clustering Coefficient\n",
        "mp.figure(figsize=(16, 10))\n",
        "for node in all_nodes:\n",
        "    y_values = [vals_iter1_clus[node], vals_iter2_clus[node]]\n",
        "    mp.plot(iterations, y_values, 'o-', label=f\"Node {node}\")\n",
        "mp.xlabel('Iterations')\n",
        "mp.ylabel('Clustering Coefficient')\n",
        "mp.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "mp.title('Clustering Coefficient Evolution')\n",
        "mp.xticks(iterations)\n",
        "mp.show()\n",
        "\n",
        "# Plotting the modularity score history\n",
        "mp.figure(figsize=(10, 6))\n",
        "# The x-axis is just the steps: 0 (original), 1 (first split), 2 (second split)\n",
        "x_axis_modularity = list(range(len(modularity_scores)))\n",
        "mp.plot(x_axis_modularity, modularity_scores, 'o-')\n",
        "mp.xlabel('Algorithm Step (0 = Original Graph)')\n",
        "mp.ylabel('Modularity Score')\n",
        "mp.title('Modularity Score per Split')\n",
        "mp.xticks(x_axis_modularity)\n",
        "mp.show()\n"
      ]
    }
  ]
}